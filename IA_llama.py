import streamlit as st
from openai import OpenAI

st.set_page_config(layout="wide")  # Configura√ß√£o para layout de p√°gina amplo

st.title("Chat com OpenAI")

# Inicialize o cliente OpenAI
client = OpenAI(
    api_key="LL-rZdxy5UFL4evTVeC6H1Jzuph00H08neiKQUGm3HSYOm1qMD4T8YxonRYedIH6856",
    base_url="https://api.llama-api.com"
)

# Hist√≥rico de conversa
conversation_history = []

# Fun√ß√£o para enviar mensagem e obter resposta
def enviar_mensagem(pergunta):
    # Enviar a mensagem para a IA e obter a resposta
    response = client.chat.completions.create(
        model="llama-13b-chat",
        messages=[
            {"role": "system", "content": "Ol√°! Sou um especialista em Python, Pandas, PySpark e AWS."},
            {"role": "user", "content": pergunta}
        ]
    )
    return response.choices[0].message.content

# Interface Streamlit para envio de pergunta
pergunta = st.text_input("Digite sua pergunta para a IA:", key="input_pergunta")

# Enviar a pergunta para a IA quando o usu√°rio pressionar Enter
if pergunta:
    # Adicionar a pergunta ao hist√≥rico de conversa
    conversation_history.append(("üôé‚Äç‚ôÇÔ∏è:", pergunta))
    # Envie a pergunta para a IA e obtenha a resposta
    resposta = enviar_mensagem(pergunta)
    # Adicionar a resposta ao hist√≥rico de conversa
    conversation_history.append(("ü§ñ:", resposta))

# Exibir hist√≥rico de conversa
st.subheader("Hist√≥rico de Conversa")
for role, message in conversation_history:
    st.write(role, message)
